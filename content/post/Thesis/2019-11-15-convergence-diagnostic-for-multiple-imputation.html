---
title: Convergence Diagnostic for Multiple Imputation
author: admin
date: '2019-11-15'
categories:
  - MSc Thesis
tags:
  - Convergence
  - MICE
  - ShinyMICE
slug: convergence-diagnostic-for-multiple-imputation
linktitle: 2019 11 15 Convergence Diagnostic for Multiple Imputation
lastmod: '2019-11-15T16:01:41+01:00'
type: "post"
# menu:
#  example:
#    name: posts
#    weight: 1
---



<p>This file describes how convergence diagnostic <span class="math inline">\(\widehat{R}\)</span> is computed in the simulation study I ran for my Research Report. <span class="math inline">\(\widehat{R}\)</span> is also called ‘potential scale reduction factor’ or ‘Gelman-Rubin statistic’. It tells us how much the variance of an estimate could be shrunken down if we would have run infinitely many iterations.</p>
<div id="step-1-impute-some-data" class="section level1">
<h1>Step 1: Impute some data</h1>
<p>It’s easiest to show how <span class="math inline">\(\widehat{R}\)</span> is computed by applying it on a simple example. Load the nhanes data and impute the variables with missingness.</p>
<pre class="r"><code># load required packages/functions
library(magrittr)
library(mice)</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## 
## Attaching package: &#39;mice&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     cbind, rbind</code></pre>
<pre class="r"><code>source(&quot;C:/Users/User/Desktop/shinyMice/Simulation/Functions/Convergence.R&quot;)
source(&quot;C:/Users/User/Desktop/shinyMice/Simulation/Functions/Convergence_supplement.R&quot;)

# set parameters
maxit &lt;- 10
n.var &lt;- 3 

# run imputation
imp &lt;- mice(nhanes[,-1], maxit = maxit, print = F)</code></pre>
</div>
<div id="step-2-evaluate-the-functions-to-use" class="section level1">
<h1>Step 2: Evaluate the functions to use</h1>
<p>We are going to compute <span class="math inline">\(\widehat{R}\)</span> values per imputed variable. As recommended by Vehtari et al. (2019), we compute split-half, rank-normalized <span class="math inline">\(\widehat{R}\)</span> values for the bulk and the tails of the distribution. For the latter, we need to fold the imputation chains before splitting them in half and rank-normalizing them. Then, <span class="math inline">\(\widehat{R}\)</span> is computed for both (bulk and tails). The highest of these two <span class="math inline">\(\widehat{R}\)</span> values is extracted. This is performed for each of the imputed variables, and only the maximum <span class="math inline">\(\widehat{R}\)</span> value across variables is reported.</p>
<p>The rhat_function function is the wrapper that performs all of this. Within the function, we call 4 other functions (explaination below): fold_sims(), split_chains(), z_scale(), and get.rhat().</p>
<pre class="r"><code># show the contents of the function
rhat_function</code></pre>
<pre><code>## function (imp, maxit, n.var = 4, moment = &quot;mean&quot;) 
## {
##     rhat &lt;- numeric(length = n.var)
##     names(rhat) &lt;- attr(imp$chainMean, &quot;dimnames&quot;)[[1]]
##     if (moment == &quot;mean&quot;) {
##         sims &lt;- imp$chainMean
##     }
##     else if (moment == &quot;variance&quot;) {
##         sims &lt;- imp$chainVar
##     }
##     for (v in 1:n.var) {
##         rhat_bulk &lt;- sims[v, , ] %&gt;% split_chains() %&gt;% z_scale() %&gt;% 
##             get.rhat(maxit = maxit)
##         rhat_tail &lt;- sims[v, , ] %&gt;% fold_sims() %&gt;% split_chains() %&gt;% 
##             z_scale() %&gt;% get.rhat(maxit = maxit)
##         rhat[v] &lt;- max(rhat_bulk, rhat_tail)
##     }
##     return(rhat)
## }</code></pre>
<p>The first function inside rhat_function is split_chains(). This ‘chops’ the chains in two, to assess trending within chains.</p>
<pre class="r"><code># show the contents of the function
split_chains</code></pre>
<pre><code>## function (sims) 
## {
##     niter &lt;- dim(sims)[1]
##     if (niter &lt; 4) 
##         return(sims)
##     half &lt;- niter/2
##     cbind(sims[1:floor(half), ], sims[ceiling(half + 1):niter, 
##         ])
## }</code></pre>
<p>Then the halved chains are rank-normalized.</p>
<pre class="r"><code># show the contents of the function
z_scale</code></pre>
<pre><code>## function (x) 
## {
##     S &lt;- length(x)
##     r &lt;- rank(x, ties.method = &quot;average&quot;)
##     z &lt;- qnorm((r - 1/2)/S)
##     if (!is.null(dim(x))) {
##         z &lt;- array(z, dim = dim(x), dimnames = dimnames(x))
##     }
##     z
## }</code></pre>
<p>To detect non-convergence in the tails, <span class="math inline">\(\widehat{R}\)</span> is also computed on the folded chains (which are also split and rank-normalized).</p>
<pre class="r"><code># show the contents of the function
fold_sims</code></pre>
<pre><code>## function (sims) 
## {
##     abs(sims - median(sims))
## }</code></pre>
<p>Only then do we get to the actual <span class="math inline">\(\widehat{R}\)</span> function. In the get.rhat function, the following equations are applied:</p>
<p>"In the equations below, <span class="math inline">\(N\)</span> is the number of draws per chain, <span class="math inline">\(M\)</span> is the number of chains, and <span class="math inline">\(S = MN\)</span> is the total number of draws from all chains. For each scalar summary of interest <span class="math inline">\(\theta\)</span>, we compute <span class="math inline">\(B\)</span> and <span class="math inline">\(W\)</span>, the between- and within-chain variances:</p>
<p><span class="math display">\[\begin{align*}
B =\frac{N}{M-1} \sum_{m=1}^{M}\left(\bar{\theta}^{(\cdot m)}-\bar{\theta}^{(\cdot \cdot)}\right)^{2}, 
\text { where } \bar{\theta}^{(\cdot m)}=\frac{1}{N} \sum_{n=1}^{N} \theta^{(n m)}, 
\text { and } \bar{\theta}^{(\cdot \cdot)}=\frac{1}{M} \sum_{m=1}^{M} \bar{\theta}^{(\cdot m)} \\
W =\frac{1}{M} \sum_{m=1}^{M} s_{j}^{2}, 
\text { where } s_{m}^{2}=\frac{1}{N-1} \sum_{n=1}^{N}\left(\theta^{(n m)}-\bar{\theta}^{(\cdot m)}\right)^{2}&quot;. 
\text{ Vehtari et al., 2019, p. 5} 
\end{align*}\]</span></p>
<p>The between and within chain variances are computed from the chain means of the mids object, that underwent the previous transformations (folding, splitting, rank-normalizing). The average of the chain means per imputation <span class="math inline">\(m\)</span> is <span class="math inline">\(\bar{\theta}^{(\cdot m)}\)</span>. The average of these <span class="math inline">\(m\)</span> values is <span class="math inline">\(\bar{\theta}^{(\cdot \cdot)}\)</span>. <span class="math inline">\(N\)</span> is the number of iterations (‘maxit’). So we compute <span class="math inline">\(B\)</span> as <code>maxit * var(apply(sims, 2, mean))</code>. And <span class="math inline">\(W\)</span> is computed as <code>mean(apply(sims, 2, var))</code>.</p>
<p>To get <span class="math inline">\(\widehat{R}\)</span> we need to compute the weighted average of <span class="math inline">\(B\)</span> and <span class="math inline">\(W\)</span>, <span class="math inline">\(\widehat{\operatorname{var}}^{+}\)</span>, and evaluate this against the within chain variance W. The weighted average is is computed as follows:</p>
<p><span class="math display">\[\begin{equation*}
\widehat{\operatorname{var}}^{+}(\theta | y)=\frac{N-1}{N} W+\frac{1}{N} B,
\end{equation*}\]</span></p>
<p>Then finally, potential scale reduction factor <span class="math inline">\(\widehat{R}\)</span> is obtained as:</p>
<p><span class="math display">\[\begin{equation*}
\widehat{R}=\sqrt{\frac{\widehat{\operatorname{var}}^{+}(\theta | y)}{W}}.
\end{equation*}\]</span></p>
<p><span class="math inline">\(\widehat{R}\)</span> is computed for each variable with the function ‘get.rhat()’.</p>
<pre class="r"><code># show the contents of the function
get.rhat</code></pre>
<pre><code>## function (sims, maxit = maxit) 
## {
##     var_between &lt;- maxit * var(apply(sims, 2, mean))
##     var_within &lt;- mean(apply(sims, 2, var))
##     rhat &lt;- sqrt((var_between/var_within + maxit - 1)/maxit)
##     return(rhat)
## }</code></pre>
</div>
<div id="step-3-apply-these-functions-to-get-widehatr-values" class="section level1">
<h1>Step 3: Apply these functions to get <span class="math inline">\(\widehat{R}\)</span> values</h1>
<p>Now we know what’s happening, let’s apply it.</p>
<pre class="r"><code>rhat_function(imp, maxit, n.var = n.var)</code></pre>
<pre><code>##      bmi      hyp      chl 
## 1.101684 1.058439 1.155748</code></pre>
<p>This <span class="math inline">\(\widehat{R}\)</span> value is nice and high, but I also got values below one. Which is theoretically impossible.</p>
</div>
<div id="so-my-question-to-you-is-how-is-it-possible-that-we-can-obtain-widehatr-values-1" class="section level1">
<h1>So my question to you is: How is it possible that we can obtain <span class="math inline">\(\widehat{R}\)</span> values &lt; 1?</h1>
</div>
